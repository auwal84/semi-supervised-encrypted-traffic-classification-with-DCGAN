{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " semi_GAN_in keras",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auwal84/semi-supervised-encrypted-traffic-classification-with-DCGAN/blob/master/semi_GAN_in_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoFCaQeM7cRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1841e099-52b3-40be-9fde-468213bcf360"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncGJCzricLz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6asfkjW78nh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg00m3JIJC0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# connect to github repo \n",
        "from getpass import getpass\n",
        "import urllib\n",
        "user = 'ausan84'\n",
        "password = getpass('Password:')\n",
        "repo_name = 'semi-supervised-encrypted-traffic-classification-with-DCGAN\n",
        "'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhJkGYDRfORP",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKUgSbYXfgbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fetch a single <1MB file using the raw GitHub URL.\n",
        "!curl --remote-name \\\n",
        "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
        "     --location https://api.github.com/repos/jakevdp/PythonDataScienceHandbook/contents/notebooks/data/california_cities.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp2HQ8vhNCUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "276b2231-052a-46ab-cae3-b3e1b7eaeae0"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg8PI0QN94oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWpK7l4J-z_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    train_data = np.load('TrainPIMset20.npy')\n",
        "    train_labels = np.load('TrainPIMlabels20.npy')\n",
        "    test_data = np.load('TestPIMset20.npy')\n",
        "    test_labels = np.load('testPIMlabels20.npy')\n",
        "    return (train_data,train_labels),(test_data,test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iZaH7EAyHTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data,train_labels),(test_data,test_labels) = load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYerv8I6nQrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20a87d89-5aad-4d10-fb8a-52ae8361b31f"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 20, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-RKk3sRnQMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvxqIhKDnrxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QviPNvzFnskY",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFqZIj7G-6XS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = tf.cast(train_data,tf.float32)\n",
        "train_data = tf.reshape(train_data,[-1,20,3,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkPBIkpQyo7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = tf.cast(train_data,tf.float32)\n",
        "train_data = tf.reshape(train_data,[-1,20,3,1])\n",
        "\n",
        "train_labels = tf.cast(train_labels,tf.int32)\n",
        "train_labels = tf.one_hot(train_labels,4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fSUoj_0oAyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = tf.cast(test_labels,tf.int32)\n",
        "test_labels = tf.one_hot(test_labels,4)\n",
        "test_data = tf.cast(test_data,tf.float32)\n",
        "test_data = tf.reshape(test_data,[-1,20,3,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0irHtefSXWQ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SrT5hVOoc6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca87e327-83bf-4e41-dca1-b0a3d171519e"
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([60000, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpdI3SDPEPog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 4\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "latent_dim =1920\n",
        "INPUT_SHAPE = (20,3,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYe7OD_nEWxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data,train_labels))\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE,drop_remainder = True)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data,test_labels)).batch(BATCH_SIZE,  drop_remainder = True)                                                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El_-OnSXihrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw1soMp6ox5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo8vc65B8XJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fcdmq0gEarl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(60*1*16, use_bias=False, input_shape=(latent_dim,)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU(alpha = 1))\n",
        "      \n",
        "    model.add(tf.keras.layers.Reshape((20, 3, 16)))\n",
        "    assert model.output_shape == (None, 20, 3, 16) # Note: None is the batch size\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2DTranspose(8, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None,20, 3, 8)  \n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(4, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None,20, 3, 4)    \n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None,20, 3, 1)\n",
        "  \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzviHl1BHkZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "ec4fcefd-fece-4097-8a8e-e502e7947e1e"
      },
      "source": [
        "g_model =make_generator_model()\n",
        "g_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 960)               1843200   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 960)               3840      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 960)               0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 20, 3, 16)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 20, 3, 8)          3200      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 20, 3, 8)          32        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 20, 3, 8)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTr (None, 20, 3, 4)          800       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 20, 3, 4)          16        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 20, 3, 4)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTr (None, 20, 3, 1)          100       \n",
            "=================================================================\n",
            "Total params: 1,851,188\n",
            "Trainable params: 1,849,244\n",
            "Non-trainable params: 1,944\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quCAohswGUwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def make_discriminator_model():\n",
        "    input = keras.Input(shape=(INPUT_SHAPE))\n",
        "    x= keras.layers.Dropout(0.4)(input)\n",
        "    x= keras.layers.Conv2D(32,kernel_size=(5,5),strides = (1,1),padding = 'same')(x)\n",
        "    x = keras.layers.LeakyReLU()(x)\n",
        "    x = keras.layers.Dropout(0.4)(x)\n",
        "    x= keras.layers.Conv2D(64,kernel_size =(3,3),strides =(1,1),padding='same')(x)\n",
        "    x= keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.LeakyReLU(0.2)(x)\n",
        "    x = keras.layers.Conv2D(128,kernel_size=(2,2),strides = (1,1),padding='same')(x)\n",
        "    x = keras.layers.LeakyReLU(0.2)(x)\n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    #x = keras.layers.Dense(4)(x)\n",
        "    model = Model(input,x,name='discriminator')\n",
        "    return model\n",
        "\n",
        "   \n",
        "\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fmVA0mB6SP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "216bd32d-a808-47b0-e500-ab4de15c47bd"
      },
      "source": [
        "d_model = make_discriminator_model()\n",
        "d_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 20, 3, 1)]        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 20, 3, 1)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 20, 3, 32)         832       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 20, 3, 32)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 20, 3, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 20, 3, 64)         18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 20, 3, 64)         256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 20, 3, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 20, 3, 128)        32896     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 20, 3, 128)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 128)               0         \n",
            "=================================================================\n",
            "Total params: 52,480\n",
            "Trainable params: 52,352\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giftczDzbmJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dense = keras.layers.Dense(5)\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
        "precision = tf.keras.metrics.Precision()\n",
        "recall = tf.keras.metrics.Recall()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fodi7xmGwTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#discriminator loss\n",
        "def loss_values(d_real_features,fake_features,labels):\n",
        "    \n",
        "    epsilon = 1e-8\n",
        "    real_logits = dense(d_real_features)\n",
        "    real_prob = tf.nn.softmax( real_logits)\n",
        "    fake_logits =dense(fake_features)\n",
        "    fake_prob = tf.nn.softmax( fake_logits)\n",
        "    def d_loss_fn():\n",
        "      \n",
        "      tmp = tf.nn.softmax_cross_entropy_with_logits(logits = real_logits,\n",
        "                                                  labels = labels)\n",
        "      labeled_mask = np.zeros([BATCH_SIZE], dtype = np.float32)\n",
        "      labeled_count = np.int(BATCH_SIZE * 0.8)\n",
        "      labeled_mask[range(labeled_count)] = 1.0\n",
        "      D_L_supervised = tf.reduce_sum(labeled_mask * tmp) / tf.reduce_sum(labeled_mask)\n",
        "      #unsupervised loss\n",
        "     \n",
        "      prob_real_be_real = 1 - real_prob[:, -1] + epsilon\n",
        "      tmp_log = tf.math.log(prob_real_be_real)\n",
        "      D_L_unsupervised1 = -1 * tf.reduce_mean(tmp_log)\n",
        "      # data is fake\n",
        "      #d_fake_prob = tf.nn.softmax(fake_logits)\n",
        "      prob_fake_be_fake = fake_prob[:, -1] + epsilon\n",
        "      tmp_log = tf.math.log(prob_fake_be_fake)\n",
        "      D_L_unsupervised2 = -1 * tf.reduce_mean(tmp_log)\n",
        "      \n",
        "\n",
        "      disc_loss = D_L_supervised + D_L_unsupervised1 + D_L_unsupervised2\n",
        "      return disc_loss\n",
        "    def g_loss_fn():\n",
        "     prob_fake_be_real = 1 - fake_prob[:, -1] + epsilon\n",
        "     tmp_log =  tf.math.log(prob_fake_be_real)\n",
        "     G_L1 = -1 * tf.reduce_mean(tmp_log)\n",
        "\n",
        "     real_moments = tf.reduce_mean(d_real_features, axis = 0)\n",
        "     generated_moments = tf.reduce_mean(fake_features, axis = 0)\n",
        "     G_L2 = tf.reduce_mean(tf.abs(real_moments - generated_moments))\n",
        "     gen_loss = G_L1 +G_L2\n",
        "     return G_L2\n",
        "  \n",
        "    train_accuracy.update_state(labels,real_prob )\n",
        "    precision.update_state(labels,real_prob)\n",
        "    recall.update_state(labels,real_prob)\n",
        "    d_loss = d_loss_fn()\n",
        "    g_loss = g_loss_fn()\n",
        "    return d_loss,g_loss,train_accuracy.result(),precision.result(),recall.result()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnXI85kbHebk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class semi_gan(Model):\n",
        "  def __init__(self,discriminator,generator, latent_dim,label_rate):\n",
        "    super(semi_gan,self).__init__()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_dim\n",
        "    self.label_rate = label_rate\n",
        "  def compile(self,d_optimizer,g_optimizer,loss_fn):\n",
        "    super(semi_gan,self).compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.loss_fn = loss_fn\n",
        "    \n",
        "  def extended_labels(self,labels):\n",
        "    extended_label = tf.concat([labels, tf.zeros([tf.shape(labels)[0], 1])], axis = 1)\n",
        "\n",
        "    return extended_label\n",
        "\n",
        "  def train_step(self,dataset):\n",
        "    features = dataset[0]\n",
        "    labels = dataset[1]\n",
        "    latent_vector = tf.random.normal(shape =(BATCH_SIZE, self.latent_dim))\n",
        "    with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
        "      generated_images = self.generator(latent_vector,training = True)\n",
        "      real_features = self.discriminator(features,training=True)\n",
        "      fake_features = self.discriminator(generated_images, training = True)\n",
        "      labels = self.extended_labels(labels)\n",
        "      d_loss,g_loss,train_acc,prec,rec = self.loss_fn(real_features,fake_features,labels)\n",
        "    d_grad = d_tape.gradient(d_loss,self.discriminator.trainable_variables)\n",
        "    g_grad = g_tape.gradient(g_loss,self.generator.trainable_variables)\n",
        "    self.d_optimizer.apply_gradients(zip(d_grad,self.discriminator.trainable_variables))\n",
        "    self.g_optimizer.apply_gradients(zip(g_grad,self.generator.trainable_variables))\n",
        "    \n",
        "    return {\"d_loss\": d_loss, \"g_loss\": g_loss,\"train_accuracy\":train_acc,\"precision\":prec,\"recall\":rec}\n",
        "  \n",
        "  #evaluate step\n",
        "  def test_step(self,dataset):\n",
        "    features = dataset[0]\n",
        "    labels = dataset[1]\n",
        "    latent_vector = tf.random.normal(shape =(BATCH_SIZE, self.latent_dim))\n",
        "    with tf.GradientTape() as d_tape, tf.GradientTape() as g_tape:\n",
        "      generated_images = self.generator(latent_vector,training = False)\n",
        "      real_features = self.discriminator(features,training=False)\n",
        "      fake_features = self.discriminator(generated_images, training = False)\n",
        "      labels = self.extended_labels(labels)\n",
        "      d_loss,g_loss,acc,prec,rec = self.loss_fn(real_features,fake_features,labels)\n",
        "    d_grad = d_tape.gradient(d_loss,self.discriminator.trainable_variables)\n",
        "    g_grad = g_tape.gradient(g_loss,self.generator.trainable_variables)\n",
        "    self.d_optimizer.apply_gradients(zip(d_grad,self.discriminator.trainable_variables))\n",
        "    self.g_optimizer.apply_gradients(zip(g_grad,self.generator.trainable_variables))\n",
        "    return {\"d_loss\": d_loss, \"g_loss\": g_loss,\"test_accuracy\":acc,\"test precision\":prec,\"test recall\":rec}\n",
        "\n",
        "      \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Z-E4MlEKvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "disc_optimizer = keras.optimizers.Adam(1e-4)\n",
        "gen_optimizer = keras.optimizers.Adam(1e-4)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzeMGKFoHn8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan =semi_gan(discriminator=d_model,generator=g_model,latent_dim=latent_dim,label_rate =0.8) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShKjY5yNP9g_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiJEM06biOEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gan.compile(d_optimizer=disc_optimizer,\n",
        "            g_optimizer= gen_optimizer,loss_fn= loss_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BtUfXl7SzbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a call backs\n",
        "class GAN_monitor(keras.callbacks.Callback):\n",
        "  def __init__(self,validation_data):\n",
        "    super(GAN_monitor,self).__init__()\n",
        "    self.dataset = validation_data\n",
        "  def on_each_end(self,epoch, logs = None):\n",
        "    features = self.dataset[0]\n",
        "    labels = self.dataset[1]\n",
        "    labels = tf.concat([labels, tf.zeros([tf.shape(labels)[0], 1])], axis = 1)\n",
        "    t_real_features = self.model.discriminator(features)\n",
        "    t_real_logits = dense(t_real_features)\n",
        "    t_real_prob = tf.nn.softmax(t_real_logits)\n",
        "    acc = accuracy(labels,t_real_prob)\n",
        "    prec = precision(labels,t_real_prob)\n",
        "    rec = recall(labels,t_real_prob)\n",
        "    print('epoch: %d, | validation_acc: %f,precision: %f,recall:%f' %(epoch,accuracy.result().numpy,precision.result().numpy(),recall.result().numpy()))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaBe1tGmDojc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "cbk = GAN_monitor(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ps7UHL2j7xd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "58a2a3c4-9d36-49be-bd87-965a2502daf7"
      },
      "source": [
        "\n",
        "history = gan.fit(train_dataset,epochs=epochs,validation_data = test_dataset.take(1000),callbacks=[cbk])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "234/234 [==============================] - 10s 41ms/step - d_loss: 0.4026 - g_loss: 0.6178 - train_accuracy: 0.7958 - precision: 0.8469 - recall: 0.7514 - val_d_loss: 0.7957 - val_g_loss: 0.2373 - val_test_accuracy: 0.7959 - val_test precision: 0.8470 - val_test recall: 0.7514\n",
            "Epoch 2/10\n",
            "234/234 [==============================] - 10s 41ms/step - d_loss: 0.3926 - g_loss: 0.6187 - train_accuracy: 0.7964 - precision: 0.8473 - recall: 0.7520 - val_d_loss: 0.8467 - val_g_loss: 0.2228 - val_test_accuracy: 0.7966 - val_test precision: 0.8475 - val_test recall: 0.7521\n",
            "Epoch 3/10\n",
            "234/234 [==============================] - 10s 41ms/step - d_loss: 0.3927 - g_loss: 0.6190 - train_accuracy: 0.7970 - precision: 0.8478 - recall: 0.7527 - val_d_loss: 0.7842 - val_g_loss: 0.2385 - val_test_accuracy: 0.7972 - val_test precision: 0.8480 - val_test recall: 0.7527\n",
            "Epoch 4/10\n",
            "234/234 [==============================] - 9s 41ms/step - d_loss: 0.3909 - g_loss: 0.6215 - train_accuracy: 0.7977 - precision: 0.8483 - recall: 0.7533 - val_d_loss: 0.7802 - val_g_loss: 0.2509 - val_test_accuracy: 0.7979 - val_test precision: 0.8484 - val_test recall: 0.7534\n",
            "Epoch 5/10\n",
            "234/234 [==============================] - 9s 41ms/step - d_loss: 0.3898 - g_loss: 0.6249 - train_accuracy: 0.7983 - precision: 0.8488 - recall: 0.7540 - val_d_loss: 0.8064 - val_g_loss: 0.2421 - val_test_accuracy: 0.7985 - val_test precision: 0.8489 - val_test recall: 0.7540\n",
            "Epoch 6/10\n",
            "234/234 [==============================] - 10s 41ms/step - d_loss: 0.3552 - g_loss: 0.6244 - train_accuracy: 0.7990 - precision: 0.8492 - recall: 0.7546 - val_d_loss: 0.7828 - val_g_loss: 0.2499 - val_test_accuracy: 0.7992 - val_test precision: 0.8494 - val_test recall: 0.7547\n",
            "Epoch 7/10\n",
            " 31/234 [==>...........................] - ETA: 6s - d_loss: 0.0741 - g_loss: 1.2448 - train_accuracy: 0.7993 - precision: 0.8495 - recall: 0.7548"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-f098b66d2e77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1spmJsJkaZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6d8b1b01-6502-4a4b-e66e-7d5d892550bb"
      },
      "source": [
        "gan.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46/46 [==============================] - 2s 35ms/step - d_loss: 2.0948 - g_loss: 0.3264 - test_accuracy: 0.7302 - test precision: 0.8184 - test recall: 0.6507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cuZz_B_waRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxPKf12gAoN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}